{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Collab_test.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHCb55xeVY1T",
        "colab_type": "text"
      },
      "source": [
        "Mount Google Drive , copy and extract data, checkout or pull to get the latest code from github."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ET06QtscMHL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "dda4b8b0-2903-4e05-90fe-5079502e4d7b"
      },
      "source": [
        "import os, time\n",
        "\n",
        "colab_data_dir = \"/content/data/\"\n",
        "\n",
        "if not os.path.exists(colab_data_dir):\n",
        "  !mkdir {colab_data_dir}\n",
        "  print(\"Data folder created.\")\n",
        "\n",
        "if not os.path.exists(\"/gdrive\"):\n",
        "  print(\"Mounting google drive\")\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive')\n",
        "print(\"Google drive is mounted at /gdrive\")\n",
        "  \n",
        "start_time = time.time()\n",
        "if not os.path.exists(os.path.join(colab_data_dir, \"300W-LP\")):  \n",
        "  print(\"Copying 300W-LP.zip...\")\n",
        "  !cp -n /gdrive/My\\ Drive/colab_workspace/advertima/data/300W-LP.zip {colab_data_dir}\n",
        "  print(\"Copied to {}\\nExtracting...\".format(colab_data_dir))\n",
        "  !unzip -qq -n /content/data/300W-LP.zip -d  {colab_data_dir}  \n",
        "  %rm {os.path.join(colab_data_dir, \"300W-LP.zip\")}\n",
        "elapsed_time = time.time() - start_time\n",
        "print(\"{} is ready ({:.1f} sec)\".format(os.path.join(colab_data_dir, \"300W-LP\"), elapsed_time))\n",
        "  \n",
        "start_time = time.time()\n",
        "if not os.path.exists(os.path.join(colab_data_dir, \"AFLW2000-3D\")):\n",
        "  print(\"Copying AFLW2000-3D.zip...\")\n",
        "  %cp -n /gdrive/My\\ Drive/colab_workspace/advertima/data/AFLW2000-3D.zip {colab_data_dir}\n",
        "  print(\"Copied to {}\\nExtracting...\".format(colab_data_dir))\n",
        "  !unzip -qq -n /content/data/AFLW2000-3D.zip -d {colab_data_dir}  \n",
        "  %rm {os.path.join(colab_data_dir, \"AFLW2000-3D.zip\")}\n",
        "elapsed_time = time.time() - start_time\n",
        "print(\"{} is ready ({:.1f} sec)\".format(os.path.join(colab_data_dir, \"AFLW2000-3D\"), elapsed_time))\n",
        "\n",
        "%cd /content\n",
        "if not os.path.exists(\"/content/deep-head-pose\"):\n",
        "  # Clone the entire repo.\n",
        "  !git clone -l -s https://github.com/emredog/deep-head-pose.git deep-head-pose\n",
        "  %cd deep-head-pose/code\n",
        "else:\n",
        "  %cd deep-head-pose/code\n",
        "  !git pull\n",
        "\n",
        "  \n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/deep-head-pose/code\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 18 (delta 13), reused 11 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (18/18), done.\n",
            "From https://github.com/emredog/deep-head-pose\n",
            "   6122034..4868859  master     -> origin/master\n",
            "Updating 6122034..4868859\n",
            "Fast-forward\n",
            " Collab_test.ipynb     | 1744 \u001b[32m+++++++++++++++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m--\u001b[m\n",
            " code/datasets.py      |  251 \u001b[32m+++++\u001b[m\u001b[31m--\u001b[m\n",
            " code/hopenet.py       |   31 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " code/train_hopenet.py |   12 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " code/utils.py         |  104 \u001b[32m++\u001b[m\u001b[31m-\u001b[m\n",
            " 5 files changed, 1995 insertions(+), 147 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFrtaMc5N4nV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import train_hopenet as trainer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEfE_JgvnMfO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "a0efaf9f-9e9f-4481-ada6-f94b9d875410"
      },
      "source": [
        "!python train_hopenet.py --num_epochs 1 --batch_size 128 --lr 10e-5 --dataset Pose_300W_LP --data_dir /content/data --alpha 1 "
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\n",
            "100% 102502400/102502400 [00:01<00:00, 102010721.58it/s]\n",
            "Loading data.\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:209: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n",
            "Traceback (most recent call last):\n",
            "  File \"train_hopenet.py\", line 106, in <module>\n",
            "    pose_dataset = datasets.Pose_300W_LP(args.data_dir, args.filename_list, transformations)\n",
            "  File \"/content/deep-head-pose/code/datasets.py\", line 126, in __init__\n",
            "    filename_list = get_list_from_filenames(filename_path)\n",
            "  File \"/content/deep-head-pose/code/datasets.py\", line 18, in get_list_from_filenames\n",
            "    with open(file_path) as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: ''\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYXph7EKq5St",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "d687997f-c0b4-465a-b0f8-77c64c16e931"
      },
      "source": [
        "!python train_hopenet.py --help\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: train_hopenet.py [-h] [--gpu GPU_ID] [--num_epochs NUM_EPOCHS]\n",
            "                        [--batch_size BATCH_SIZE] [--lr LR]\n",
            "                        [--dataset DATASET] [--data_dir DATA_DIR]\n",
            "                        [--filename_list FILENAME_LIST]\n",
            "                        [--output_string OUTPUT_STRING] [--alpha ALPHA]\n",
            "                        [--snapshot SNAPSHOT]\n",
            "\n",
            "Head pose estimation using the Hopenet network.\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --gpu GPU_ID          GPU device id to use [0]\n",
            "  --num_epochs NUM_EPOCHS\n",
            "                        Maximum number of training epochs.\n",
            "  --batch_size BATCH_SIZE\n",
            "                        Batch size.\n",
            "  --lr LR               Base learning rate.\n",
            "  --dataset DATASET     Dataset type.\n",
            "  --data_dir DATA_DIR   Directory path for data.\n",
            "  --filename_list FILENAME_LIST\n",
            "                        Path to text file containing relative paths for every\n",
            "                        example.\n",
            "  --output_string OUTPUT_STRING\n",
            "                        String appended to output snapshots.\n",
            "  --alpha ALPHA         Regression loss coefficient.\n",
            "  --snapshot SNAPSHOT   Path of model snapshot.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDT5DJ0Rr3fq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}